# yaml-language-server: $schema=https://raw.githubusercontent.com/defenseunicorns/uds-cli/v0.19.0/uds.schema.json
kind: UDSBundle
metadata:
  name: software-factory-nutanix-rke2
  description: A UDS bundle for deploying a software factory to an RKE2 cluster
  # x-release-please-start-version
  version: "0.5.1"
  # x-release-please-end
  architecture: amd64

x-extra-volume-mounts: &extra-volume-mounts
  - name: trust-bundle
    mountPath: /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem
    subPath: "ca-bundle.crt"
    readOnly: true
  - name: trust-bundle
    mountPath: /etc/pki/ca-trust/extracted/java/cacerts
    subPath: "ca-bundle.jks"
    readOnly: true

x-extra-volumes: &extra-volumes
  - name: trust-bundle
    configMap:
      name: trust-bundle
      defaultMode: 0644

x-gitlab-init-security-context: &gitlab-init-security-context
  privileged: true
  readOnlyRootFilesystem: false
  runAsUser: 0
  allowPrivilegeEscalation: true
  runAsNonRoot: false

packages:
  # Zarf init
  - name: init
    repository: ghcr.io/zarf-dev/packages/init
    ref: v0.43.1
    overrides:
      zarf-seed-registry:
        docker-registry:
          variables:
            - name: REGISTRY_CA_BUNDLE
              path: caBundle
              default: ""
      zarf-registry:
        docker-registry:
          variables:
            - name: REGISTRY_CA_BUNDLE
              path: caBundle
              default: ""
            - name: REGISTRY_REPLICA_COUNT
              path: replicaCount
              default: 3

  - name: nutanix-csi
    path: ../../build
    ref: 3.0.0
    overrides:
      nutanix-csi-storage:
        nutanix-csi-storage:
          variables:
            - name: CSI_NODE_TOLERATIONS
              description: "Tolerations to apply to the CSI node pods."
              path: node.tolerations
              default:
                - effect: NoSchedule
                  key: dedicated-gitaly-node
                  operator: Exists

  - name: cert-manager
    path: ../../build
    ref: 0.0.1

  - name: trust-manager
    path: ../../build
    ref: 0.0.1

  - name: trust-bundles
    path: ../../build
    ref: 0.0.1

  # MetalLB
  - name: metallb
    repository: ghcr.io/defenseunicorns/packages/metallb
    ref: 0.0.5-amd64

  - name: core
    repository: ghcr.io/defenseunicorns/packages/uds/core
    ref: 0.31.2-registry1
    optionalComponents:
      - metrics-server
    overrides:
      grafana:
        grafana:
          values:
            - path: extraVolumes
              value: *extra-volumes
            - path: extraVolumeMounts
              value: *extra-volume-mounts
          variables:
            - name: GRAFANA_RESOURCE_CONFIG
              path: resources
              default:
                requests:
                  cpu: 500m
                  memory: 512Mi
                limits:
                  cpu: 2
                  memory: 2Gi
      kube-prometheus-stack:
        kube-prometheus-stack:
          variables:
            - name: PROMETHEUS_RESOURCE_CONFIG
              path: prometheus.prometheusSpec.resources
              default:
                requests:
                  cpu: 1
                  memory: 2Gi
                limits:
                  cpu: 4
                  memory: 8Gi
          values:
            - path: kube-state-metrics.resources
              value:
                requests:
                  cpu: 20m
                  memory: 128Mi
                limits:
                  cpu: 500m
                  memory: 512Mi
      velero:
        velero:
          variables:
            - name: VELERO_RESOURCE_CONFIG
              path: resources
              description: "Velero Resource Config"
              default:
                requests:
                  cpu: 500m
                  memory: 128Mi
                limits:
                  cpu: 1
                  memory: 2Gi
          values:
            - path: configuration.features
              value: EnableCSI
            - path: snapshotsEnabled
              value: true
            - path: configuration.volumeSnapshotLocation
              value:
                - name: default
                  provider: aws
                  config:
                    region: "us-east-1"
                  credential:
                    name: "velero-bucket-credentials"
                    key: "cloud"
            - path: schedules
              value:
                uds-jira-backup:
                  disabled: false
                  schedule: "0 3 * * *"
                  useOwnerReferencesInBackup: false
                  template:
                    csiSnapshotTimeout: 0s
                    includeClusterResources: true
                    snapshotVolumes: true
                    includedNamespaces:
                      - jira
                    ttl: "240h"
                uds-confluence-backup:
                  disabled: false
                  schedule: "0 3 * * *"
                  useOwnerReferencesInBackup: false
                  template:
                    csiSnapshotTimeout: 0s
                    includeClusterResources: true
                    snapshotVolumes: true
                    includedNamespaces:
                      - confluence
                    ttl: "240h"
                uds-mattermost-backup:
                  disabled: false
                  schedule: "0 3 * * *"
                  useOwnerReferencesInBackup: false
                  template:
                    csiSnapshotTimeout: 0s
                    includeClusterResources: true
                    snapshotVolumes: true
                    includedNamespaces:
                      - mattermost
                    ttl: "240h"
                uds-nexus-backup:
                  disabled: false
                  schedule: "0 3 * * *"
                  useOwnerReferencesInBackup: false
                  template:
                    csiSnapshotTimeout: 0s
                    includeClusterResources: true
                    snapshotVolumes: true
                    includedNamespaces:
                      - nexus
                    ttl: "240h"
                uds-gitlab-backup:
                  disabled: false
                  schedule: "0 3 * * *"
                  useOwnerReferencesInBackup: false
                  template:
                    csiSnapshotTimeout: 0s
                    includeClusterResources: true
                    snapshotVolumes: true
                    includedNamespaces:
                      - gitlab
                    ttl: "240h"
            - path: extraVolumes
              value: *extra-volumes
            - path: extraVolumeMounts
              value: *extra-volume-mounts
      keycloak:
        keycloak:
          values:
            - path: "devMode"
              value: "false"
            - path: "autoscaling.enabled"
              value: "false"
            - path: "persistence.providers.enabled"
              value: "true"
            - path: "persistence.accessMode"
              value: "ReadWriteMany"
            - path: "persistence.storageClassName"
              value: "nutanix-dynamicfile"
          variables:
            - name: KEYCLOAK_HA_ENABLED
              path: "autoscaling.enabled"
              default: true
            - name: KEYCLOAK_DB_USERNAME
              description: "keycloak database username"
              path: postgresql.username
              default: "postgres"
            - name: KEYCLOAK_DB_PASSWORD
              description: "keycloak database password"
              path: postgresql.password
              default: "replace-me"
            - name: KEYCLOAK_DB_NAME
              description: "keycloak database name"
              path: postgresql.database
              default: "keycloakdb"
            - name: KEYCLOAK_DB_ENDPOINT
              description: "keycloak database name"
              path: postgresql.host
              default: "postgresql"
            - name: KEYCLOAK_INSECURE_ADMIN_PASSWORD_GENERATION
              description: "Generate an insecure admin password for dev/test"
              path: insecureAdminPasswordGeneration.enabled
            - name: KEYCLOAK_RESOURCE_CONFIG
              description: "Keycloak Resource Config"
              path: resources
              default:
                requests:
                  cpu: 400m
                  memory: 512Mi
                limits:
                  cpu: "1"
                  memory: 2Gi
      loki:
        loki:
          values:
            # Override default dns service name for Loki Gateway
            - path: "global.dnsService"
              value: "rke2-coredns-rke2-coredns"
            - path: backend.extraVolumes
              value: *extra-volumes
            - path: backend.extraVolumeMounts
              value: *extra-volume-mounts
            - path: gateway.extraVolumes
              value: *extra-volumes
            - path: gateway.extraVolumeMounts
              value: *extra-volume-mounts
            - path: write.extraVolumes
              value: *extra-volumes
            - path: write.extraVolumeMounts
              value: *extra-volume-mounts
            - path: read.extraVolumes
              value: *extra-volumes
            - path: read.extraVolumeMounts
              value: *extra-volume-mounts
          variables:
            - name: LOKI_CHUNKS_BUCKET
              description: "The object storage bucket for Loki chunks"
              path: loki.storage.bucketNames.chunks
              default: "loki-chunks-bucket"
            - name: LOKI_RULER_BUCKET
              description: "The object storage bucket for Loki ruler"
              path: loki.storage.bucketNames.ruler
              default: "loki-ruler-bucket"
            - name: LOKI_ADMIN_BUCKET
              description: "The object storage bucket for Loki admin"
              path: loki.storage.bucketNames.admin
              default: "loki-admin-bucket"
            - name: LOKI_S3_ENDPOINT
              description: "The S3 endpoint"
              path: loki.storage.s3.endpoint
            - name: LOKI_S3_REGION
              description: "The S3 region"
              path: loki.storage.s3.region
            - name: LOKI_S3_ACCESS_KEY_ID
              description: "The S3 Access Key ID"
              path: loki.storage.s3.accessKeyId
            - name: LOKI_S3_SECRET_ACCESS_KEY
              path: loki.storage.s3.secretAccessKey
              description: "The S3 Secret Access Key"
            - name: LOKI_WRITE_REPLICAS
              path: write.replicas
              description: "Loki write replicas"
              default: "1"
            - name: LOKI_READ_REPLICAS
              path: read.replicas
              description: "Loki read replicas"
              default: "1"
            - name: LOKI_BACKEND_REPLICAS
              path: backend.replicas
              description: "Loki backend replicas"
              default: "1"
            - name: LOKI_WRITE_PERSISTENCE_SIZE
              path: write.persistence.size
              description: "Loki write persistence size"
              default: 128Gi
            - name: LOKI_BACKEND_PERSISTENCE_SIZE
              path: backend.persistence.size
              description: "Loki backend persistence size"
              default: 128Gi
      istio-admin-gateway:
        uds-istio-config:
          variables:
            - name: ADMIN_TLS_CERT
              description: "The TLS cert for the admin gateway (must be base64 encoded)"
              path: tls.cert
            - name: ADMIN_TLS_KEY
              description: "The TLS key for the admin gateway (must be base64 encoded)"
              path: tls.key
      istio-tenant-gateway:
        gateway:
          values:
            - path: "service.ports"
              value:
                - name: status-port
                  port: 15021
                  protocol: TCP
                  targetPort: 15021
                - name: http2
                  port: 80
                  protocol: TCP
                  targetPort: 80
                - name: https
                  port: 443
                  protocol: TCP
                  targetPort: 443
                - name: tcp-ssh
                  port: 22
                  protocol: TCP
                  targetPort: 2222
        uds-istio-config:
          variables:
            - name: TENANT_TLS_CERT
              description: "The TLS cert for the tenant gateway (must be base64 encoded)"
              path: tls.cert
            - name: TENANT_TLS_KEY
              description: "The TLS key for the tenant gateway (must be base64 encoded)"
              path: tls.key
            - name: TENANT_HOST_LIST
              path: tls.servers.tenant.hosts  # The tenant subpath is in the override here: https://github.com/defenseunicorns/uds-core/blob/main/src/istio/values/config-tenant.yaml#L11
              default:
                - "*"
                - "*.nexus"  # To add the multiple nexus sub-domain registries to the tenant gateway. Do not attempt *.*.nexus, Nexus only supports first-level subdomain routing.
      vector:
        vector:
          variables:
            - name: VECTOR_RESOURCE_CONFIG
              description: "Vector Resource Config"
              path: resources
              default:
                requests:
                  cpu: 100m
                  memory: 256Mi
                limits:
                  cpu: 1
                  memory: 2Gi

  # NOTE -- depends on hardcoded PVC name(s) in core.keycloak
  - name: keycloak-config-wrapper
    path: ../../build
    ref: 0.0.2

  # Additional manifests needed
  - name: additional-manifests
    path: ../../build
    ref: 0.0.2

  # Gitlab
  - name: gitlab-valkey
    repository: ghcr.io/defenseunicorns/packages/uds/valkey
    ref: 8.0.1-uds.2-upstream
    overrides:
      valkey:
        uds-valkey-config:
          namespace: gitlab-valkey
          values:
            - path: custom
              value:
                - direction: Ingress
                  selector:
                    app.kubernetes.io/name: valkey
                  remoteNamespace: gitlab
                  port: 6379
                  description: "Ingress from GitLab to Valkey read/write ports"
                - direction: Ingress
                  selector:
                    app.kubernetes.io/name: valkey
                  remoteNamespace: gitlab
                  port: 26379
                  description: "Ingress from GitLab to Valkey Sentinel"
            - path: copyPassword
              value:
                enabled: true
                namespace: gitlab
                secretName: gitlab-redis
                secretKey: password
          variables:
            - name: GL_VALKEY_REPLICAS
              default: 3
              path: replicas
        valkey:
          namespace: gitlab-valkey
          values:
            - path: architecture
              value: replication
            - path: sentinel.enabled
              value: true
            - path: auth.enabled
              value: true
            - path: auth.sentinel
              value: true

  - name: gitlab-pgbouncer-rw
    repository: ghcr.io/defenseunicorns/packages/uds/pgbouncer
    ref: 1.21.0-uds.5-registry1
    exports:
      - name: GITLAB_DB_USERNAME
      - name: GITLAB_DB_PASSWORD
    overrides:
      pgbouncer:
        pgbouncer:
          namespace: gitlab-pgbouncer-rw
          variables:
            - name: GITLAB_DB_USERNAME
              path: config.adminUser
              description: "pgbouncer admin username. Should match Gitlab postgres database username"
            - name: GITLAB_DB_PASSWORD
              path: config.adminPassword
              description: "pgbouncer admin password. Should match GitLab postgres database password"
            - name: PGBOUNCER_DATABASES
              path: config.databases
              description: "Database configuration for pgbouncer"
            - name: PGBOUNCER_REPLICA_COUNT
              path: replicaCount
              description: "Number of desired PgBouncer pods"
              default: 3
            - name: PGBOUNCER_CONFIG
              path: config.pgbouncer
              description: "Optional variable that should only need configured if the default pgbouncer configuration is inadequate."
        uds-pgbouncer-config:
          namespace: gitlab-pgbouncer-rw
          values:
            - path: pgbouncer.ingress
              value:
                - remoteNamespace: gitlab
            - path: pgbouncer.peerauth
              value:
                permissive: true
                port: 5432
            - path: postgres.internal
              value: false
              description: "Postgres DB is external to cluster, so set this to false to all egress traffic out of cluster"

  # Temporary read replica pgbouncer cluster. Not ideal setup for gitlab's internal read replica loadbalancing logic.
  # This will configure multiple pgbouncer instances to connect to the read replicas via HA proxy.
  # GitLab recommends a single read replica pgbouncer per postgres replica and to configure gitlab to load balance reads to each replica directly.
  # https://docs.gitlab.com/ee/administration/postgresql/database_load_balancing.html
  - name: gitlab-pgbouncer-ro
    repository: ghcr.io/defenseunicorns/packages/uds/pgbouncer
    ref: 1.21.0-uds.5-registry1
    imports:
      - name: GITLAB_DB_USERNAME
        package: gitlab-pgbouncer-rw
      - name: GITLAB_DB_PASSWORD
        package: gitlab-pgbouncer-rw
    overrides:
      pgbouncer:
        pgbouncer:
          namespace: gitlab-pgbouncer-ro
          variables:
            - name: GITLAB_DB_USERNAME
              path: config.adminUser
              description: "pgbouncer admin username. Should match Gitlab postgres database username"
            - name: GITLAB_DB_PASSWORD
              path: config.adminPassword
              description: "pgbouncer admin password. Should match GitLab postgres database password"
            - name: PGBOUNCER_DATABASES
              path: config.databases
              description: "Database configuration for pgbouncer"
            - name: PGBOUNCER_REPLICA_COUNT
              path: replicaCount
              description: "Number of desired PgBouncer pods"
              default: 3
            - name: PGBOUNCER_CONFIG
              path: config.pgbouncer
              description: "Optional variable that should only need configured if the default pgbouncer configuration is inadequate."
        uds-pgbouncer-config:
          namespace: gitlab-pgbouncer-ro
          values:
            - path: pgbouncer.ingress
              value:
                - remoteNamespace: gitlab
            - path: pgbouncer.peerauth
              value:
                permissive: true
                port: 5432
            - path: postgres.internal
              value: false
              description: "Postgres DB is external to cluster, so set this to false to all egress traffic out of cluster"

  - name: gitlab-object-store
    path: ../../build
    ref: 0.0.1

  - name: gitlab-database-secret
    path: ../../build
    ref: 0.0.1
    imports:
      - name: GITLAB_DB_PASSWORD
        package: gitlab-pgbouncer-rw

  - name: gitlab
    repository: ghcr.io/defenseunicorns/packages/uds/gitlab
    ref: 17.6.1-uds.0-upstream
    imports:
      - name: GITLAB_DB_USERNAME
        package: gitlab-pgbouncer-rw

    overrides:
      gitlab:
        uds-gitlab-config:
          values:
            - path: storage.internal
              value: false
            - path: storage.createSecret.enabled
              value: false
            - path: postgres.internal
              value: false
            - path: redis
              value:
                internal: true
                selector:
                  app.kubernetes.io/name: valkey
                namespace: gitlab-valkey
                port: 6379
            - path: redis.sentinel.enabled
              value: true
            - path: ssh.enabled
              value: true
        uds-gitlab-settings:
          values:
            - path: settingsJob.application.enabled_git_access_protocol
              value: all
        gitlab:
          values:
            - path: global.certificates.customCAs
              value:
                - configMap: trust-bundle
                  keys:
                    - ca-bundle.crt
            - path: gitlab.webservice.init.containerSecurityContext
              value: *gitlab-init-security-context
            - path: gitlab.toolbox.init.containerSecurityContext
              value: *gitlab-init-security-context
            - path: gitlab.sidekiq.init.containerSecurityContext
              value: *gitlab-init-security-context
            - path: gitlab.gitlab-pages.init.containerSecurityContext
              value: *gitlab-init-security-context
            - path: gitlab.gitlab-exporter.init.containerSecurityContext
              value: *gitlab-init-security-context
            - path: global.redis.host
              value: mymaster
            - path: global.redis.port
              value: 6379
            - path: global.redis.auth.enabled
              value: true
            - path: global.redis.sentinelAuth.enabled
              value: true
            - path: gitlab.gitlab-shell.enabled
              value: true
            # See gitlab's additional manifests, this priority class prevents gitaly from being evicted due to node pressure.
            - path: gitlab.gitaly.priorityClassName
              value: "gitlab-gitaly"
            - path: gitlab.gitaly.securityContext.fsGroupChangePolicy  # https://docs.gitlab.com/ee/administration/gitaly/kubernetes.html#persistent-volume-permissions
              value: OnRootMismatch
            - path: gitlab.gitaly.cgroups.initContainer.image.tag
              value: v17.6.1
            - path: global.psql.host
              description: "GitLab DB host should point to kubernetes service for read/write pgbouncer cluster."
              value: "pgbouncer.gitlab-pgbouncer-rw.svc.cluster.local"
          variables:
            - name: MIGRATIONS_RESOURCES
              description: "Gitlab Migrations Resources"
              path: "gitlab.migrations.resources"
            - name: WEBSERVICE_REPLICAS
              description: "Gitlab Webservice Min Replicas"
              path: "gitlab.webservice.minReplicas"
            - name: WEBSERVICE_WORKERS
              description: "Gitlab Webservice Worker Count"
              path: "gitlab.webservice.workerProcesses"
            - name: WEBSERVICE_HPA
              description: "Gitlab Webservice HPA settings"
              path: "gitlab.webservice.hpa"
            - name: WEBSERVICE_RESOURCES
              description: "Gitlab Webservice Resources"
              path: "gitlab.webservice.resources"
            - name: WORKHORSE_RESOURCES
              description: "Gitlab Workhorse Resources"
              path: "gitlab.webservice.workhorse.resources"
            - name: SIDEKIQ_REPLICAS
              description: "Gitlab Sidekiq Min Replicas"
              path: "gitlab.sidekiq.minReplicas"
            - name: SIDEKIQ_HPA
              description: "Gitlab Sidekiq HPA settings"
              path: "gitlab.sidekiq.hpa"
            - name: SIDEKIQ_RESOURCES
              description: "Gitlab Sidekiq Resources"
              path: "gitlab.sidekiq.resources"
            - name: GITALY_RESOURCES
              description: "Gitlab Gitaly Resources"
              path: "gitlab.gitaly.resources"
            - name: GITALY_CGROUPS  # Set this per the docs, per the resources you've given to gitaly, and per your repo makeup - https://docs.gitlab.com/ee/administration/gitaly/kubernetes.html#constrain-git-processes-resource-usage
              path: "gitlab.gitaly.cgroups"
              default:
                enabled: false
            - name: REGISTRY_REPLICAS
              description: "Gitlab Registry Min Replicas"
              path: "registry.hpa.minReplicas"
            - name: SHELL_REPLICAS
              description: "Gitlab Shell Min Replicas"
              path: "gitlab.gitlab-shell.minReplicas"
            - name: TOLERATIONS
              description: "Tolerations to allow gitaly to schedule on tainted nodes."
              path: gitlab.gitaly.tolerations
              default:
                - effect: NoSchedule
                  key: dedicated-gitaly-node
                  operator: Exists
            - name: AFFINITY
              description: "Affinity settings to prefer scheduling on dedicated gitaly nodes and avoid nodes already running gitaly."
              path: gitlab.gitaly.affinity
              default:
                podAntiAffinity:
                  preferredDuringSchedulingIgnoredDuringExecution:
                    - weight: 100
                      podAffinityTerm:
                        labelSelector:
                          matchExpressions:
                            - key: app
                              operator: In
                              values:
                                - gitaly
                        topologyKey: kubernetes.io/hostname
                nodeAffinity:
                  preferredDuringSchedulingIgnoredDuringExecution:
                    - weight: 1
                      preference:
                        matchExpressions:
                          - key: dedicated
                            operator: In
                            values:
                              - gitaly-node
            # https://docs.gitlab.com/charts/charts/gitlab/gitaly/ - every name becomes a stateful storage set (gitaly instance)
            - name: GITALY_SHARD_NAMES
              path: global.gitaly.internal.names # Gitlab uses the global top-value to set subcharts: https://gitlab.com/gitlab-org/charts/gitlab/-/blob/master/values.yaml?ref_type=heads#L184
              default:
                - "default"  # Gitlab requires that the first shard always be named `default`: https://docs.gitlab.com/ee/administration/gitaly/configure_gitaly.html?tab=Helm+chart+%28Kubernetes%29#gitlab-requires-a-default-repository-storage
            - name: GITLAB_VALKEY_SENTINELS
              path: global.redis.sentinels
              default:
                - host: valkey-node-0.valkey-headless.gitlab-valkey.svc.cluster.local
                  port: 26379
                - host: valkey-node-1.valkey-headless.gitlab-valkey.svc.cluster.local
                  port: 26379
                - host: valkey-node-2.valkey-headless.gitlab-valkey.svc.cluster.local
                  port: 26379
            # https://docs.gitlab.com/charts/charts/globals.html#postgresql-load-balancing - configure read replica load balancing hosts list and fine tuning if needed.
            - name: GITLAB_DB_LOAD_BALANCING
              path: global.psql.load_balancing
              description: "GitLab read replica load balancing configuration"
              default: # Since we are currently using in cluster pgbouncer for read replicas, set default to only use hostname for kubernetes service for read pgbouncer cluster
                hosts:
                  - "pgbouncer.gitlab-pgbouncer-ro.svc.cluster.local"
            - name: MIGRATIONS_DB_ENDPOINT
              description: "Postgres hostname/IP for gitlab migrations job to run against. Must bypass pgbouncer for migrations so this must be either HA proxy or direct connection to postgres primary."
              path: "gitlab.migrations.psql.host"
            - name: MIGRATIONS_DB_PORT
              description: "Postgres port for gitlab migrations job."
              path: "gitlab.migrations.psql.port"
            - name: TOOLBOX_DB_ENDPOINT
              description: "Postgres hostname/IP for gitlab toolbox. Must bypass pgbouncer for backups so this must be either HA proxy or direct connection to postgres primary."
              path: "gitlab.toolbox.psql.host"
            - name: TOOLBOX_DB_PORT
              description: "Postgres port for gitlab toolbox."
              path: "gitlab.toolbox.psql.port"
            - name: GITLAB_DB_USERNAME
              description: "postgres username"
              path: "global.psql.username"
              default: "postgres"

  # Gitlab Runner
  - name: gitlab-runner
    repository: ghcr.io/defenseunicorns/packages/uds/gitlab-runner
    ref: 17.1.0-uds.1-registry1
    overrides:
      gitlab-runner:
        gitlab-runner:
          values:
            - path: volumes
              value: *extra-volumes
            - path: volumeMounts
              value: *extra-volume-mounts

  - name: sonarqube
    repository: ghcr.io/defenseunicorns/packages/uds/sonarqube
    ref: 10.7.0-uds.2-registry1
    overrides:
      sonarqube:
        uds-sonarqube-config:
          values:
            - path: postgres.internal
              value: false
            - path: postgres.password
              value: "###ZARF_VAR_SONARQUBE_DB_PASSWORD###"
            - path: "jdbcOverwrite.jdbcUsername"
              value: "###ZARF_VAR_SONARQUBE_DB_USERNAME###"
            - path: extraVolumes
              value: *extra-volumes
            - path: extraVolumeMounts
              value: *extra-volume-mounts
        sonarqube:
          values:
            - path: extraVolumes
              value: *extra-volumes
            - path: extraVolumeMounts
              value: *extra-volume-mounts

  - name: jira
    repository: ghcr.io/defenseunicorns/packages/uds/jira
    ref: 10.1.2-uds.0-registry1
    overrides:
      jira:
        uds-jira-config:
          values:
            - path: postgres.internal
              value: false
            - path: postgres.username
              value: "###ZARF_VAR_JIRA_DB_USERNAME###"
            - path: postgres.password
              value: "###ZARF_VAR_JIRA_DB_PASSWORD###"
            - path: volumes.additional
              value: *extra-volumes
            - path: jira.additionalVolumeMounts
              value: *extra-volume-mounts
        jira:
          values:
            - path: volumes.additional
              value: *extra-volumes
            - path: jira.additionalVolumeMounts
              value: *extra-volume-mounts
          variables:
            - name: JIRA_LOCAL_HOME_ENABLED
              path: "volumes.localHome.persistentVolumeClaim.create"
              description: "Local Home Toggle"
              default: "true"
            - name: JIRA_RWO_STORAGE_CLASS
              path: "volumes.localHome.persistentVolumeClaim.storageClassName"
              description: "RWO storage class name"
            - name: JIRA_LOCAL_HOME_SIZE
              path: "volumes.localHome.persistentVolumeClaim.resources.requests.storage"
              description: "Storage size"
              default: "128Gi"
              # 1-2k users
            - name: JIRA_RESOURCE_CONFIG
              path: "jira.resources"
              default:
                container:
                  requests:
                    cpu: "100m"
                    memory: "2Gi"
                  limits:
                    cpu: "8"
                    memory: "16Gi"
                jvm:
                  maxHeap: "6g"

  - name: confluence
    repository: ghcr.io/defenseunicorns/packages/uds/confluence
    ref: 1.20.0-uds.4-registry1
    overrides:
      confluence:
        uds-confluence-config:
          values:
            - path: postgres.internal
              value: false
            - path: postgres.username
              value: "###ZARF_VAR_CONFLUENCE_DB_USERNAME###"
            - path: postgres.password
              value: "###ZARF_VAR_CONFLUENCE_DB_PASSWORD###"
            - path: additionalFiles
              value:
                - name: trust-bundle
                  mountPath: /etc/pki/ca-trust/extracted/java/cacerts
                  key: "ca-bundle.jks"
                  type: configMap
        confluence:
          values:
            - path: additionalFiles
              value:
                - name: trust-bundle
                  mountPath: /var/ssl
                  key: "ca-bundle.jks"
                  type: configMap
          variables:
            - name: CONFLUENCE_LOCAL_HOME_ENABLED
              path: "volumes.localHome.persistentVolumeClaim.create"
              description: "Local Home Toggle"
              default: "true"
            - name: CONFLUENCE_RWO_STORAGE_CLASS
              path: "volumes.localHome.persistentVolumeClaim.storageClassName"
              description: "RWO storage class name"
            - name: CONFLUENCE_LOCAL_HOME_SIZE
              path: "volumes.localHome.persistentVolumeClaim.resources.requests.storage"
              description: "Storage size"
              default: "128Gi"
            - name: CONFLUENCE_RESOURCE_CONFIG
              path: "confluence.resources"
              default:
                container:
                  requests:
                    cpu: "2"
                    memory: "2Gi"
                  limits:
                    cpu: "4"
                    memory: "8Gi"
                jvm:
                  maxHeap: "6g"

   # Mattermost
  - name: mattermost
    repository: ghcr.io/defenseunicorns/packages/uds/mattermost
    ref: 10.1.3-uds.0-registry1
    overrides:
      mattermost:
        mattermost-enterprise-edition:
          values:
            - path: mattermostApp.extraVolumes
              value: *extra-volumes
            - path: mattermostApp.extraVolumeMounts
              value:
                - name: trust-bundle
                  mountPath: /etc/ssl/certs/ca.crt
                  subPath: "ca-bundle.crt"
                  readOnly: true
        uds-mattermost-config:
          values:
            - path: postgres.internal
              value: false
          variables:
            - name: OBJECT_STORE_SECURE
              path: "objectStorage.secure"
              description: "Object storage ssl"
              default: "false"
            - name: OBJECT_STORE_ENDPOINT
              path: "objectStorage.endpoint"
              description: "Object storage endpoint"
            - name: OBJECT_STORE_BUCKET
              path: "objectStorage.bucket"
              description: "Object storage bucket"
              default: "mattermost-bucket"
            - name: OBJECT_STORE_REGION
              path: "objectStorage.region"
              description: "Object storage region"
              default: "us-east-1"
            - name: DB_ENDPOINT
              path: "postgres.host"
              description: "Postgres DB endpoint"
            - name: DB_USERNAME
              path: "postgres.username"
              description: "Postgres DB username"
              default: "postgres"
            - name: DB_NAME
              path: "postgres.dbName"
              description: "Postgres DB database name"
              default: "mattermostdb"
            - name: DB_OPTIONS
              path: "postgres.connectionOptions"
              description: "Postgres DB connection options"
              default: "?connect_timeout=10"
            # 1-2k users
            - name: MATTERMOST_RESOURCE_CONFIG
              path: mattermostApp.resources
              description: "Mattermost Resource Config"
              default:
                requests:
                  cpu: 100m
                  memory: 256Mi
                limits:
                  cpu: 2
                  memory: 4Gi

  # Nexus
  - name: nexus
    repository: ghcr.io/defenseunicorns/packages/uds/nexus
    ref: 3.72.0-uds.0-registry1
    overrides:
      nexus:
        nexus:
          variables:
            # Medium <50 repositories
            - name: NEXUS_RESOURCE_CONFIG
              path: nexus.resources
              default:
                requests:
                  cpu: 2
                  memory: 4Gi
                limits:
                  cpu: 8
                  memory: 16Gi
            - name: STORAGE_SIZE
              path: persistence.storageSize
              default: 8Gi
          values:
            - path: sso.realm
              value:
                - "NexusAuthenticatingRealm"
                - "SamlRealm"
                - "User-Token-Realm"
                - "NuGetApiKey"
            - path: nexus.docker.enabled
              value: true
            - path: deployment.additionalVolumes
              value: *extra-volumes
            - path: deployment.additionalVolumeMounts
              value: *extra-volume-mounts
        uds-nexus-config:
          variables:
            - name: NEXUS_SSO_ENABLED
              path: "sso.enabled"
          values:
            - path: additionalNetworkExposures
              value:
                - service: nexus-repository-manager
                  description: Expose the subdomain for segmented docker registries.
                  selector:
                    app.kubernetes.io/instance: nexus
                  gateway: tenant
                  host: "*.nexus"
                  port: 8081
